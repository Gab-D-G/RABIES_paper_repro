**Analysis reproducibility (part 2 of the manuscript)**

Instructions for reproducing analysis outputs from RABIES:
1. The analyses were conducted with RABIES version 0.5.0. For compatibility, with the version 0.4.7 used for preprocessing, some folder names had to be manually modified, namely: the confounds_datasink/ folder was renamed to motion_datasink/, and the confounds_datasink/confounds_csv/ folder was renamed to motion_datasink/motion_params_csv
2. Edit the prep_run_CR.py python script:
    * Change the `dataset_dict[dataset]['rabies_out']` folder path to correspond to the preprocessing output folder for the given dataset.
    * Change the `diagnosis_out=f'/scratch/m/mchakrav/desgab/multicenter_diagnosis/{dataset}'` path on line 336 to provide a path leading to the desired output folder for analysis
    * Change the path to the RABIES Singularity image `/home/m/mchakrav/desgab/singularity_images/rabies-0.5.0-dev.sif` on line 373 and 419
3. **Execute confound correction:** Create a sub-folder for each dataset, naming it according to the dataset name (e.g. 117_Cryo_mediso_v), inside the folder you provided to replace `/scratch/m/mchakrav/desgab/multicenter_diagnosis/`. Move prep_run_CR.py inside this folder, then execute the script with `python prep_run_CR.py`. This will generate within each dataset sub folder a file named run_CR.sh, and a set of run_optimized_CR{#}.sh. The run_CR.sh script will conduct the confound correction stage for all variants of confound correction investigated, and each run_optimized_CR script corresponds to an iteration of the optimization of the correction for this dataset. Execute those scripts to reproduce confound correction.
4. In the prepare_scanlist.py, change the `failed_list=['sub-jgrAesAWc21L_ses-1_task-rest_acq-EPI_run-1_bold', 'sub-212_ses-1_task-rest_acq-EPI_bold']` list to provide instead an updated list of scans which failed preprocessing (see step #4 in reproducing RABIES preprocessing)
5. Edit the prep_run_analysis.py python script (and modify prep_run_analysis_no_QC.py as well with similar instructions):
    * Change the `dataset_dict[dataset]['rabies_out']` folder path to correspond to the preprocessing output folder for the given dataset.
    * Change the `diagnosis_out=f'/scratch/m/mchakrav/desgab/multicenter_diagnosis/{dataset}'` path on line 117 and 160 to provide a path leading to the desired output folder for analysis (must be the same as previously defined for confound correction)
    * Change the path to the RABIES Singularity image `/home/m/mchakrav/desgab/singularity_images/rabies-0.5.0-dev.sif` on line 137,143,183 and 189. 
    * Change the atlas folder path `-B /home/m/mchakrav/desgab/atlases:/atlases:ro`, as well as the path to the seeds from --seed_list and maps from --seed_prior_list to provide a new path to the corresponding files which can be downloaded from https://doi.org/10.17605/OSF.IO/GT7EX. These changes must be applied in the singularity commands beginning on lines 140 and 186.
6. **Execution of analysis and RABIES diagnosis:** Move prep_run_analysis.py inside the folder you provided to replace `/scratch/m/mchakrav/desgab/multicenter_diagnosis/`, and execute the script with `python prep_run_analysis.py`. This will generate run_analysis.sh scripts within each dataset sub-folder, which can be executed to generate analysis and data diagnosis outputs across all CR variants. Similarly, run_analysis_optimized_CR{#}.sh script will be generated to conduct analysis for a given iteration of the confound correction optimization. The same can be done for prep_run_analysis_no_QC.py, and the run_analysis_no_QC.sh files generated, to conduct analysis without applying scan-level quality control exclusion thresholds.
